{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommend Movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we will use the ratings.csv and the movies.csv files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the ratings.csv, the file lists each movie that has been rated when by an user. We have the following columns: <br> <br>\n",
    "**userId** - user <br>\n",
    "**movieId** - movie <br>\n",
    "**rating** - what number value a user gives to this particular movie <br>\n",
    "**timestamp** - when this rating was given <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the movies.csv file, we will have the descriptors of the movies. Here is the list of columns and what they represent: <br> <br> \n",
    "**movieId** - movie <br>\n",
    "**title** - the title of the movie <br>\n",
    "**genres** - one or more tags to describe the movie <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Completed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This script will download the necessary data for training to run.\n",
    "\"\"\"\n",
    "\n",
    "from io import BytesIO\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "movielens_data_file_url = (\n",
    "'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'\n",
    ")\n",
    "req = requests.get(movielens_data_file_url)\n",
    "print('Downloading Completed')\n",
    "\n",
    "file = zipfile.ZipFile(BytesIO(req.content))\n",
    "dir = os.getcwd()\n",
    "file.extractall(dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer='he_normal',\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer='he_normal',\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return tf.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 610, Number of Movies: 9724, Min rating: 0.5, Max rating: 5.0\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/silvergenova/Library/Python/3.8/lib/python/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"Adam/gradients/PartitionedCall:1\", shape=(None,), dtype=int64), values=Tensor(\"Adam/gradients/PartitionedCall:0\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"Adam/gradients/PartitionedCall:2\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n",
      "/Users/silvergenova/Library/Python/3.8/lib/python/site-packages/tensorflow/python/framework/indexed_slices.py:444: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"Adam/gradients/PartitionedCall:7\", shape=(None,), dtype=int64), values=Tensor(\"Adam/gradients/PartitionedCall:6\", shape=(None, 50), dtype=float32), dense_shape=Tensor(\"Adam/gradients/PartitionedCall:8\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1056/1056 [==============================] - 4s 3ms/step - loss: 0.6439 - val_loss: 0.6207\n",
      "Epoch 2/5\n",
      "1056/1056 [==============================] - 3s 3ms/step - loss: 0.6177 - val_loss: 0.6244\n",
      "Epoch 3/5\n",
      "1056/1056 [==============================] - 3s 3ms/step - loss: 0.6116 - val_loss: 0.6152\n",
      "Epoch 4/5\n",
      "1056/1056 [==============================] - 3s 3ms/step - loss: 0.6087 - val_loss: 0.6133\n",
      "Epoch 5/5\n",
      "1056/1056 [==============================] - 3s 3ms/step - loss: 0.6077 - val_loss: 0.6098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15aafed60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "curr_dir = Path(\"__file__\").parent\n",
    "movielens_dir = os.path.join(curr_dir, 'ml-latest-small')\n",
    "ratings_file = os.path.join(movielens_dir, 'ratings.csv')\n",
    "df = pd.read_csv(ratings_file)\n",
    "\n",
    "user_ids = df['userId'].unique().tolist()\n",
    "user2user_encoded = {x: i for i, x in enumerate(user_ids)}\n",
    "userencoded2user = {i: x for i, x in enumerate(user_ids)}\n",
    "movie_ids = df['movieId'].unique().tolist()\n",
    "movie2movie_encoded = {x: i for i, x in enumerate(movie_ids)}\n",
    "movie_encoded2movie = {i: x for i, x in enumerate(movie_ids)}\n",
    "df['user'] = df['userId'].map(user2user_encoded)\n",
    "df['movie'] = df['movieId'].map(movie2movie_encoded)\n",
    "\n",
    "num_users = len(user2user_encoded)\n",
    "num_movies = len(movie_encoded2movie)\n",
    "df['rating'] = df['rating'].values.astype(np.float32)\n",
    "# min and max ratings will be used to normalize the ratings later\n",
    "min_rating = min(df['rating'])\n",
    "max_rating = max(df['rating'])\n",
    "\n",
    "print(\n",
    "    'Number of users: {}, Number of Movies: {}, Min rating: {}, Max rating: {}'.format(\n",
    "        num_users, num_movies, min_rating, max_rating,\n",
    "    ),\n",
    ")\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "x = df[['user', 'movie']].values\n",
    "# Normalize the targets between 0 and 1. Makes it easy to train.\n",
    "y = df['rating'].apply(\n",
    "    lambda x: (x - min_rating) /\n",
    "    (max_rating - min_rating),\n",
    ").values\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.33)\n",
    "\n",
    "model = RecommenderNet(num_users, num_movies, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(), optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    ")\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(x_val, y_val),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 0s 779us/step\n",
      "Showing recommendations for user: 1\n",
      "====================================\n",
      "Top 10 movie recommendations\n",
      "--------------------------------\n",
      "Shawshank Redemption, The (1994) : Crime|Drama\n",
      "Rear Window (1954) : Mystery|Thriller\n",
      "One Flew Over the Cuckoo's Nest (1975) : Drama\n",
      "Brazil (1985) : Fantasy|Sci-Fi\n",
      "Godfather: Part II, The (1974) : Crime|Drama\n",
      "Amadeus (1984) : Drama\n",
      "Raging Bull (1980) : Drama\n",
      "Good Will Hunting (1997) : Drama|Romance\n",
      "Fear and Loathing in Las Vegas (1998) : Adventure|Comedy|Drama\n",
      "Snatch (2000) : Comedy|Crime|Thriller\n"
     ]
    }
   ],
   "source": [
    "movie_df = pd.read_csv(os.path.join(movielens_dir, 'movies.csv'))\n",
    "movies_watched_by_user = df[df.userId == user_id]\n",
    "movies_not_watched = movie_df[\n",
    "    ~movie_df['movieId'].isin(movies_watched_by_user.movieId.values)\n",
    "]['movieId']\n",
    "movies_not_watched = list(\n",
    "    set(movies_not_watched).intersection(set(movie2movie_encoded.keys())),\n",
    ")\n",
    "movies_not_watched = [\n",
    "    [movie2movie_encoded.get(x)] for x in movies_not_watched\n",
    "]\n",
    "user_encoder = user2user_encoded.get(user_id)\n",
    "user_movie_array = np.hstack(\n",
    "    ([[user_encoder]] * len(movies_not_watched), movies_not_watched),\n",
    ")\n",
    "ratings = model.predict(user_movie_array).flatten()\n",
    "top_ratings_indices = ratings.argsort()[-10:][::-1]\n",
    "recommended_movie_ids = [\n",
    "    movie_encoded2movie.get(movies_not_watched[x][0]) for x in top_ratings_indices\n",
    "]\n",
    "\n",
    "print(f'Showing recommendations for user: {user_id}')\n",
    "print('====' * 9)\n",
    "print('Top 10 movie recommendations')\n",
    "print('----' * 8)\n",
    "recommended_movies = movie_df[\n",
    "    movie_df['movieId'].isin(\n",
    "        recommended_movie_ids,\n",
    "    )\n",
    "]\n",
    "for row in recommended_movies.itertuples():\n",
    "    print(row.title, ':', row.genres)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
